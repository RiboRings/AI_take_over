# -*- coding: utf-8 -*-
"""AquaMonitor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/aquamonitor-0ea5fe82-876d-4c7f-b009-f33a2e7bb840.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250305/auto/storage/goog4_request%26X-Goog-Date%3D20250305T105329Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dcae2e98e4d6d2fa7e96585b8a3bc5936aa613c1c760f891fa62f691cfb436f9ce9c06f7a79cea8fa78ea75a0d2e6da620fffab46b4bbf066789e97331c4fe2c6c74738a505813707596882fdaa0beef6a6178cbb54214bd82a19445885633c381bb3ba0faf1c41f25fcfd9b36b653bd1dd73bb18503937c9021a48264d8e9d5272668fefaed169090de19b3f7149e7cb5c523f910bc8ccaeab71780b066aa1649ebb96e68d16b3a19d6339346d1c093d9676501fb2f9c426747c6dccf2d9fdd01b2c6db120dd04a9487b6fe0caadcc6d831716d4a897f255604c545c7a051bdb180e2fb8ae44e644163e4ee05eef7ffc3b7f0be75bf0a71e098ba56867fcac52
"""

from matplotlib import pyplot as plt
from huggingface_hub import hf_hub_download
from datasets import load_dataset
from sklearn.metrics import f1_score
import pandas as pd

import torch
from torch import nn
from torch.optim import Adam
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.models import vit_b_16, ViT_B_16_Weights

ds = load_dataset(
    "mikkoim/aquamonitor-jyu",
    cache_dir="/kaggle/working/"
)

hf_hub_download(
    repo_id="mikkoim/aquamonitor-jyu",
    filename="aquamonitor-jyu.parquet.gzip",
    repo_type="dataset",
    local_dir="/kaggle/working/"
)

# dataset elements can be accessed with indices. Each "row" or record
# has an image and a key that can be used to access data from the metadata table
record = ds["train"][21015]
record

img = record["jpg"]
print(record["__key__"])
img

# The keys match the rows in the metadata table
metadata = pd.read_parquet("/kaggle/working/aquamonitor-jyu.parquet.gzip")
metadata

classes = sorted(metadata["taxon_group"].unique())
class_map = {k:v for v,k in enumerate(classes)}
class_map_inv = {v:k for k,v in class_map.items()}

metadata["img"] = metadata["img"].str.removesuffix(".jpg")
label_dict = dict(zip(metadata["img"], metadata["taxon_group"].map(class_map)))

class_map_inv

IMAGE_SIZE = 224
BATCH_SIZE = 32
EPOCH_NUM = 20

tf = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.RandomHorizontalFlip(p=0.75),
    transforms.RandomVerticalFlip(p=0.75),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

def preprocess(batch):
    return {"key": batch["__key__"],
            "img": [tf(x) for x in batch["jpg"]],
            "label": torch.as_tensor([label_dict[x] for x in batch["__key__"]], dtype=torch.long)}

train_ds = ds["train"].with_transform(preprocess)
devel_ds = ds["validation"].with_transform(preprocess)

print(f"Train Size: {train_ds.num_rows}")
print(f"Devel Size: {devel_ds.num_rows}")

# plt.imshow(train_ds[2014]["img"].permute(1, 2, 0).numpy())

train_loader = DataLoader(
    train_ds,
    batch_size=BATCH_SIZE,
    shuffle=True
)

devel_loader = DataLoader(
    devel_ds,
    batch_size=BATCH_SIZE
)

model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)

model.heads.head = nn.Linear(
    in_features=model.heads.head.in_features,
    out_features=len(classes)
)

# Freeze the feature extractor parameters
for param in model.parameters():
    param.requires_grad = False

# Unfreeze the classifier head parameters
for param in model.heads.head.parameters():
    param.requires_grad = True

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.heads.head.parameters(), lr=1e-4)

scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode="min",
    factor=0.5,
    patience=5
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Initialise objects to store results
train_losses = []
train_f1s = []
devel_losses = []
devel_f1s = []
best_loss = float('inf')
best_model_weights = None

for epoch in range(EPOCH_NUM):
    model.train()
    running_loss = 0.0
    train_labels = []
    train_preds = []

    for batch in train_loader:
        images, labels = batch["img"], batch["label"]
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        # Calculate accuracy
        _, preds = torch.max(outputs.data, 1)
        train_labels.extend(labels.cpu().numpy())
        train_preds.extend(preds.cpu().numpy())

    # Calculate and store training loss and accuracy
    train_loss = running_loss / len(train_loader)
    train_f1 = f1_score(train_labels, train_preds, average='weighted')
    train_losses.append(train_loss)
    train_f1s.append(train_f1)

    # Validation phase
    model.eval()
    devel_running_loss = 0.0
    devel_labels = []
    devel_preds = []

    with torch.no_grad():
        for batch in devel_loader:
            images, labels = batch["img"], batch["label"]
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            devel_running_loss += loss.item()

            # Calculate validation F1 score
            _, preds = torch.max(outputs.data, 1)
            devel_labels.extend(labels.cpu().numpy())
            devel_preds.extend(preds.cpu().numpy())

    # Calculate and store validation loss and accuracy
    devel_loss = devel_running_loss / len(devel_loader)
    devel_f1 = f1_score(devel_labels, devel_preds, average='weighted')
    devel_losses.append(devel_loss)
    devel_f1s.append(devel_f1)

    # Step the scheduler
    scheduler.step(devel_loss)

    print(f'Epoch [{epoch+1}/{EPOCH_NUM}], lr: {scheduler.get_last_lr()[0]}, '
          f'Train Loss: {train_loss:.4f}, Train F1-Score: {train_f1:.3g}, '
          f'Devel Loss: {devel_loss:.4f}, Devel F1-Score: {devel_f1:.3g}')

    # Check if we have a new best model
    if devel_loss < best_loss:
        best_loss = devel_loss
        best_model_weights = model.state_dict()

# Restore best weights
if best_model_weights is not None:

    # Load best model
    model.load_state_dict(best_model_weights)
    # Save best model
    torch.save(best_model_weights, '/kaggle/working/fine_tuned_vit.pth')

# Plot the learning curves
plt.figure(figsize=(12, 5))

# Loss plot
plt.subplot(1, 2, 1)
plt.plot(range(1, EPOCH_NUM + 1), train_losses, label='Train Set')
plt.plot(range(1, EPOCH_NUM + 1), devel_losses, label='Devel Set')
plt.title('Loss Curve')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# F1-Score plot
plt.subplot(1, 2, 2)
plt.plot(range(1, EPOCH_NUM + 1), train_f1s, label='Train Set')
plt.plot(range(1, EPOCH_NUM + 1), devel_f1s, label='Devel Set')
plt.title('F1-Score Curve')
plt.xlabel('Epochs')
plt.ylabel('F1-Score')
plt.legend()

plt.tight_layout()