# -*- coding: utf-8 -*-
"""AquaMonitor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/aquamonitor-0ea5fe82-876d-4c7f-b009-f33a2e7bb840.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20250305/auto/storage/goog4_request%26X-Goog-Date%3D20250305T105329Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dcae2e98e4d6d2fa7e96585b8a3bc5936aa613c1c760f891fa62f691cfb436f9ce9c06f7a79cea8fa78ea75a0d2e6da620fffab46b4bbf066789e97331c4fe2c6c74738a505813707596882fdaa0beef6a6178cbb54214bd82a19445885633c381bb3ba0faf1c41f25fcfd9b36b653bd1dd73bb18503937c9021a48264d8e9d5272668fefaed169090de19b3f7149e7cb5c523f910bc8ccaeab71780b066aa1649ebb96e68d16b3a19d6339346d1c093d9676501fb2f9c426747c6dccf2d9fdd01b2c6db120dd04a9487b6fe0caadcc6d831716d4a897f255604c545c7a051bdb180e2fb8ae44e644163e4ee05eef7ffc3b7f0be75bf0a71e098ba56867fcac52
"""

from matplotlib import pyplot as plt
from huggingface_hub import hf_hub_download
from datasets import load_dataset
from sklearn.metrics import f1_score
import pandas as pd

import torch
from torch import nn
from torch.optim import Adam
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.models import resnet18, ResNet18_Weights
from torchvision.models import swin_v2_t, Swin_V2_T_Weights
from tqdm import tqdm


ds = load_dataset(
    "mikkoim/aquamonitor-jyu",
    cache_dir="Dataset/data"
)

hf_hub_download(
    repo_id="mikkoim/aquamonitor-jyu",
    filename="aquamonitor-jyu.parquet.gzip",
    repo_type="dataset",
    local_dir="."
)

# dataset elements can be accessed with indices. Each "row" or record
# has an image and a key that can be used to access data from the metadata table
record = ds["train"][21015]
record

img = record["jpg"]
print(record["__key__"])
img

# The keys match the rows in the metadata table
metadata = pd.read_parquet("aquamonitor-jyu.parquet.gzip")
metadata

classes = sorted(metadata["taxon_group"].unique())
class_map = {k:v for v,k in enumerate(classes)}
class_map_inv = {v:k for k,v in class_map.items()}

metadata["img"] = metadata["img"].str.removesuffix(".jpg")
label_dict = dict(zip(metadata["img"], metadata["taxon_group"].map(class_map)))

class_map_inv

IMAGE_SIZE = 224
BATCH_SIZE = 16
EPOCH_NUM = 30

tf = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

def preprocess(batch):
    return {"key": batch["__key__"],
            "img": [tf(x) for x in batch["jpg"]],
            "label": torch.as_tensor([label_dict[x] for x in batch["__key__"]], dtype=torch.long)}


eval_ds = ds["validation"].with_transform(preprocess)

print(f"eval Size: {eval_ds.num_rows}")

eval_loader = DataLoader(
    eval_ds,
    batch_size=BATCH_SIZE
)


model_resnet = resnet18()
in_features_resnet = model_resnet.fc.in_features
model_resnet.fc = nn.Linear(in_features_resnet, 31)


model_swin = swin_v2_t()
in_features_swin = model_swin.head.in_features
model_swin.head = nn.Linear(in_features_swin, 31)


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model_resnet.load_state_dict(torch.load("fine_tuned_resnet18.pth", map_location=device))
model_swin.load_state_dict(torch.load("model.pth", map_location=device))

model_resnet.to(device)
model_swin.to(device)

model_resnet.eval()
model_swin.eval()

eval_labels = []
eval_preds = []

with torch.no_grad():
    for batch in tqdm(eval_loader):
        images, labels = batch["img"], batch["label"]
        images, labels = images.to(device), labels.to(device)

        # Vorhersagen von Modell 1 und Modell 2
        outputs_resnet = model_resnet(images)
        outputs_swin = model_swin(images)

        # Kombinieren (z.B. arithmetisches Mittel der Logits)
        combined_outputs = (outputs_resnet + outputs_swin) / 2.0

        # Labels und Predictions sammeln
        _, preds = torch.max(combined_outputs.data, 1)
        eval_labels.extend(labels.cpu().numpy())
        eval_preds.extend(preds.cpu().numpy())


eval_f1 = f1_score(eval_labels, eval_preds, average='weighted')
print(f"F1-Score der kombinierten Vorhersagen auf dem Validierungsset: {eval_f1:.3f}")